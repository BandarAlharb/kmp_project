import streamlit as st
import time
import datetime
import uuid
import re
from difflib import SequenceMatcher
from database import save_knowledge, get_knowledge, search_knowledge
from openai_service import (
    process_knowledge, 
    generate_knowledge_tags, 
    generate_smart_questions,
    process_question_answers,
    correct_arabic_text  # Ø¥Ø¶Ø§ÙØ© ÙˆØ¸ÙŠÙØ© ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
)
from utils import get_sample_departments, format_relative_time, truncate_text

def are_questions_similar(question1, question2, threshold=0.7):
    """
    ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø³Ø¤Ø§Ù„Ø§Ù† Ù…ØªØ´Ø§Ø¨Ù‡ÙŠÙ† Ø¬ÙˆÙ‡Ø±ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø³Ù„Ø§Ø³Ù„
    ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
    
    Args:
        question1: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„
        question2: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ
        threshold: Ø¹ØªØ¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (0.0 - 1.0)ØŒ Ø­ÙŠØ« 1.0 Ù‡Ùˆ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„
        
    Returns:
        Boolean: Ù‡Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„Ø§Ù† Ù…ØªØ´Ø§Ø¨Ù‡Ø§Ù† Ø¨Ø¯Ø±Ø¬Ø© ÙƒØ§ÙÙŠØ©ØŸ
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
    def clean_question(text):
        # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
        text = re.sub(r'[ØŒ,\.ØŸ\?!]', ' ', text)
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø© (Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
        text = text.lower()
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        stop_words = ['Ù‡Ù„', 'Ù…Ø§', 'Ù…Ù†', 'ÙÙŠ', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ø¥Ù„Ù‰', 'Ù‡Ùˆ', 'Ù‡ÙŠ', 'Ø£Ùˆ', 'Ø£Ù†', 'Ø§Ù„ØªÙŠ', 'Ø§Ù„Ø°ÙŠ']
        for word in stop_words:
            text = text.replace(f' {word} ', ' ')
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    clean_q1 = clean_question(question1)
    clean_q2 = clean_question(question2)
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ù„Ù…Ø¹Ø±ÙØ© Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    similarity_ratio = SequenceMatcher(None, clean_q1, clean_q2).ratio()
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙƒÙ„Ù…Ø§Øª Ù…Ø´ØªØ±ÙƒØ© Ù…Ù‡Ù…Ø©ØŒ Ø²ÙŠØ§Ø¯Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø³ÙŠØ§Ù‚ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ©
    important_words = ['ÙƒÙ‡Ø±Ø¨Ø§Ø¡', 'ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ', 'Ø­Ø±ÙŠÙ‚', 'Ø¥ØµØ§Ø¨Ø©', 'Ø¶Ø±Ø±', 'Ù…Ø³Ø¤ÙˆÙ„', 'ØµÙŠØ§Ù†Ø©', 'Ø¥Ø¨Ù„Ø§Øº', 'ØªØµÙ„ÙŠØ­', 
                     'Ù…Ø´ÙƒÙ„Ø©', 'ØªÙ…Ø§Ø³', 'Ø¹Ø²Ù„', 'ØªÙŠØ§Ø±', 'Ù…Ø¹Ø¯Ø©', 'Ø¢Ù„Ø©', 'Ø¬Ù‡Ø§Ø²', 'Ù…ÙˆÙ‚Ø¹', 'Ù…ÙƒØ§Ù†', 'Ø·Ø§Ø¨Ù‚', 'Ø¯ÙˆØ±']
    
    # Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
    common_important_words = sum(1 for word in important_words 
                               if word in clean_q1 and word in clean_q2)
    
    # Ø²ÙŠØ§Ø¯Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
    if common_important_words > 0:
        # Ø²ÙŠØ§Ø¯Ø© Ø¨Ù†Ø³Ø¨Ø© 10% Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…Ù‡Ù…Ø© Ù…Ø´ØªØ±ÙƒØ©ØŒ Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 30%
        similarity_ratio += min(0.3, common_important_words * 0.1)
    
    # Ø¥Ø°Ø§ ØªØ¬Ø§ÙˆØ²Øª Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù†Ø¹ØªØ¨Ø± Ø§Ù„Ø³Ø¤Ø§Ù„ÙŠÙ† Ù…ØªØ´Ø§Ø¨Ù‡ÙŠÙ†
    return similarity_ratio >= threshold

def process_search_query(openai_client, db_client, query):
    """Process a search query from the user"""
    # Perform search
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
        try:
            # Ø§Ù„Ù…Ø³Ø§Ø± 1: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø£ÙƒØ«Ø± Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©
            search_results = search_knowledge(db_client, query)
            print(f"Basic search found {len(search_results)} results")
            
            # Check if we have results
            if not search_results:
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ùƒ. ÙŠØ±Ø¬Ù‰ ØªØ¬Ø±Ø¨Ø© Ù…ØµØ·Ù„Ø­Ø§Øª Ø¨Ø­Ø« Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©.",
                    "timestamp": time.time()
                })
            else:
                # Format search results
                results_text = "Ø¥Ù„ÙŠÙƒ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:\n\n"
                for i, result in enumerate(search_results[:5]):  # Limit to top 5 results
                    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø·ÙˆØ§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø©
                    timestamp = result.get("timestamp", 0)
                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¹Ø¯Ø¯ ØµØ­ÙŠØ­
                    if isinstance(timestamp, (float, int)):
                        created_time = format_relative_time(int(timestamp))
                    else:
                        created_time = "ÙˆÙ‚Øª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
                        
                    department = result.get('department', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                    employee = result.get('employee_name', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                    
                    results_text += f"**Ø§Ù„Ù†ØªÙŠØ¬Ø© {i+1}** - Ù…Ù† Ù‚Ø³Ù… {department}\n"
                    results_text += f"ØªÙ…Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ø¨ÙˆØ§Ø³Ø·Ø©: {employee} ({created_time})\n"
                    results_text += f"{truncate_text(result.get('content', ''), 350)}\n\n"
                    
                    # Add separator between results except after the last one
                    if i < len(search_results[:5]) - 1:
                        results_text += "---\n\n"
                
                # Add search results to chat history
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": results_text,
                    "timestamp": time.time()
                })
                
        except Exception as e:
            print(f"Error during search: {str(e)}")
            # Ø§Ø±Ø¬Ø¹ Ø±Ø³Ø§Ù„Ø© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªØ³Ø§Ø¹Ø¯ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": "Ø¹Ø°Ø±Ù‹Ø§ØŒ ÙˆØ§Ø¬Ù‡Ù†Ø§ Ù…Ø´ÙƒÙ„Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«. ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø¹Ø¯. Ø­Ø§ÙˆÙ„ Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹Ø±ÙØ© Ø¬Ø¯ÙŠØ¯Ø© Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø£ÙˆÙ„Ø§Ù‹.",
                "timestamp": time.time()
            })

def start_knowledge_collection(openai_client, db_client, employee_name, department, knowledge_text):
    """Start the knowledge collection process with follow-up questions"""
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…Ø¹Ø±ÙØ©..."):
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            processed_content = process_knowledge(openai_client, knowledge_text)
            
            # ØªÙ‡ÙŠØ¦Ø© Ù…ØµÙÙˆÙØ§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©
            previous_questions = []
            previous_answers = []
            
            # Ù„Ù† Ù†Ø®Ø²Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ØŒ Ø³Ù†ÙˆÙ„Ø¯ ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙÙ‚Ø· Ø¹Ù†Ø¯Ù…Ø§ Ù†Ø­ØªØ§Ø¬Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ØªØ·ÙˆØ± Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ ÙÙ‚Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI
            try:
                first_question_list = generate_smart_questions(openai_client, processed_content)
                # Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ØŒ ÙˆØ³Ù†ÙˆÙ„Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø­Ø³Ø¨ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                first_question = first_question_list[0] if first_question_list else None
            except Exception as e:
                print(f"Error generating first question: {str(e)}")
                first_question = None
                
            # Ø¥Ø°Ø§ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ØŒ ÙØ³Ù†Ø³ØªØ®Ø¯Ù… Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ù…Ù†Ø§Ø³Ø¨
            if not first_question:
                import random
                
                # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                content_lower = processed_content.lower()
                
                # Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§
                content_types = {
                    "ÙƒÙ‡Ø±Ø¨Ø§Ø¡": ["ÙƒÙ‡Ø±Ø¨Ø§Ø¡", "ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ", "ØªÙ…Ø§Ø³", "ÙÙˆÙ„Øª", "Ø£Ø³Ù„Ø§Ùƒ", "ØªÙŠØ§Ø±"],
                    "Ø­Ø§Ø¯Ø«": ["Ø­Ø§Ø¯Ø«", "Ø¥ØµØ§Ø¨Ø©", "Ø¶Ø±Ø±", "Ø®Ø·Ø±", "Ø¥Ø³Ø¹Ø§Ù", "Ø·ÙˆØ§Ø±Ø¦"],
                    "Ù…Ù†ØªØ¬": ["Ù…Ù†ØªØ¬", "Ø³Ù„Ø¹Ø©", "Ø¨Ø¶Ø§Ø¹Ø©", "Ù…Ø®Ø²ÙˆÙ†", "Ù‚Ø·Ø¹Ø©", "ØµÙ†Ù"],
                    "Ø¥Ø¬Ø±Ø§Ø¡": ["Ø¥Ø¬Ø±Ø§Ø¡", "Ø¹Ù…Ù„ÙŠØ©", "Ø®Ø·ÙˆØ§Øª", "ØªØ¹Ù„ÙŠÙ…Ø§Øª", "Ø¯Ù„ÙŠÙ„", "Ø·Ø±ÙŠÙ‚Ø©"],
                    "Ù…ÙƒØ§Ù†": ["Ù…ÙƒØ§Ù†", "Ù…ÙˆÙ‚Ø¹", "Ù…Ø¨Ù†Ù‰", "Ø·Ø§Ø¨Ù‚", "Ù…ÙƒØªØ¨", "Ù‚Ø§Ø¹Ø©", "Ø¯ÙˆØ±"],
                    "Ø´Ø®Øµ": ["Ù…ÙˆØ¸Ù", "Ø´Ø®Øµ", "Ù…Ø¯ÙŠØ±", "Ù…Ø³Ø¤ÙˆÙ„", "Ø¹Ø§Ù…Ù„", "ÙØ±ÙŠÙ‚"]
                }
                
                # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                detected_type = "Ø¹Ø§Ù…"  # Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
                max_matches = 0
                
                for content_type, keywords in content_types.items():
                    matches = sum(1 for word in keywords if word in content_lower)
                    if matches > max_matches:
                        max_matches = matches
                        detected_type = content_type
                
                # Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                questions_by_type = {
                    "ÙƒÙ‡Ø±Ø¨Ø§Ø¡": [
                        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ÙˆØªØ£Ø«ÙŠØ±Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„Ø£Ø®Ø±Ù‰ØŸ",
                        "Ù‡Ù„ ØªÙ… Ø¥Ø¨Ù„Ø§Øº Ù…Ø³Ø¤ÙˆÙ„ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŒ ÙˆÙ…Ù† Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø§Ù„Ù…Ø¹Ù†ÙŠØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­ÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§ØªØ®Ø§Ø°Ù‡Ø§ØŸ"
                    ],
                    "Ø­Ø§Ø¯Ø«": [
                        "Ù‡Ù„ Ù†ØªØ¬ Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø­Ø§Ø¯Ø« Ø£ÙŠ Ø¥ØµØ§Ø¨Ø§Øª Ø£Ùˆ Ø£Ø¶Ø±Ø§Ø±ØŒ ÙˆÙ…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§ØªØ®Ø§Ø°Ù‡Ø§ØŸ",
                        "Ù‡Ù„ ØªÙ… ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø­Ø§Ø¯Ø« ÙˆØ¥Ø¨Ù„Ø§Øº Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø¹Ù†ÙŠØ©ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§ØªØ®Ø§Ø°Ù‡Ø§ Ù„Ù…Ù†Ø¹ ÙˆÙ‚ÙˆØ¹ Ø­ÙˆØ§Ø¯Ø« Ù…Ù…Ø§Ø«Ù„Ø© Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ØŸ"
                    ],
                    "Ù…Ù†ØªØ¬": [
                        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙÙ†ÙŠØ© Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø¨Ø¯Ø§Ø¦Ù„ Ø£Ùˆ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø£Ø®Ø±Ù‰ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ØŸ"
                    ],
                    "Ø¥Ø¬Ø±Ø§Ø¡": [
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø£Ùˆ Ø´Ø±ÙˆØ· Ù…Ø³Ø¨Ù‚Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ø¥ØªÙ…Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ ØªØ­Ø¯ÙŠØ§Øª Ø£Ùˆ Ù…Ø´Ø§ÙƒÙ„ Ø´Ø§Ø¦Ø¹Ø© Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ØŸ"
                    ],
                    "Ù…ÙƒØ§Ù†": [
                        "Ù…Ø§ Ù‡ÙŠ Ø³Ø§Ø¹Ø§Øª Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù†ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ø±Ø§ÙÙ‚ Ø£Ùˆ Ù…Ø¹Ø¯Ø§Øª Ø®Ø§ØµØ© Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù†ØŸ",
                        "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø£Ùˆ Ø¬Ù‡Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¹Ù†ÙŠØ© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù†ØŸ"
                    ],
                    "Ø´Ø®Øµ": [
                        "Ù…Ø§ Ù‡ÙŠ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª ÙˆØµÙ„Ø§Ø­ÙŠØ§Øª Ù‡Ø°Ø§ Ø§Ù„Ø´Ø®Øµ ÙÙŠ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØ£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„ØªÙˆØ§ØµÙ„ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø®Ø¨Ø±Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ø´Ø®Øµ ÙˆÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù†Ù‡Ø§ØŸ"
                    ],
                    "Ø¹Ø§Ù…": [
                        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø£Ùˆ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¬Ù‡Ø§Øª Ø§ØªØµØ§Ù„ Ø£Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø®Ø±Ù‰ Ù…Ù‡Ù…Ø© ÙŠØ¬Ø¨ Ù…Ø´Ø§Ø±ÙƒØªÙ‡Ø§ Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ"
                    ]
                }
                
                # Ø§Ø®ØªÙŠØ§Ø± Ø³Ø¤Ø§Ù„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
                first_question = random.choice(questions_by_type.get(detected_type, questions_by_type["Ø¹Ø§Ù…"]))
            
            # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
            # Ù„Ø§ Ù†Ø®Ø²Ù† Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ø¦Ù„Ø© Ù…Ø­Ø¯Ø¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ØŒ Ø³Ù†ÙˆÙ„Ø¯ ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙÙŠ ÙˆÙ‚ØªÙ‡
            st.session_state.current_knowledge = {
                "original_text": knowledge_text,
                "processed_text": processed_content,
                "question_index": 0,
                "questions": [first_question],  # Ù†Ø®Ø²Ù† ÙÙ‚Ø· Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„
                "answers": [""],  # Ù…ÙƒØ§Ù† Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„
                "complete": False,
                "previous_questions": previous_questions,  # Ù„ØªØ®Ø²ÙŠÙ† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                "previous_answers": previous_answers       # Ù„ØªØ®Ø²ÙŠÙ† Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            }
            
            # ØªØ¹ÙŠÙŠÙ† ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ©
            st.session_state.conversation_mode = "knowledge_collection"
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ‚ Ù…Ø®ØµØµ
            content_type_detected = ""
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ‚ Ø´Ø®ØµÙŠ
            content_lower = processed_content.lower()
            
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            if "ÙƒÙ‡Ø±Ø¨Ø§Ø¡" in content_lower or "ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ" in content_lower or "ØªÙ…Ø§Ø³" in content_lower:
                content_type_detected = "Ø£Ø±Ù‰ Ø£Ù† Ù‡Ø°Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù…Ø´ÙƒÙ„Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©. "
            elif "Ø­Ø±ÙŠÙ‚" in content_lower or "Ø¯Ø®Ø§Ù†" in content_lower:
                content_type_detected = "Ø´ÙƒØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø­Ø§Ø¯Ø« Ø§Ù„Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø³Ù„Ø§Ù…Ø©. "
            elif "Ø¹Ø·Ù„" in content_lower or "ØµÙŠØ§Ù†Ø©" in content_lower:
                content_type_detected = "Ø£ÙÙ‡Ù… Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ØªØ­ØªØ§Ø¬ Ù„Ù„ØµÙŠØ§Ù†Ø©. "
            elif "Ø¯ÙˆØ±" in content_lower or "Ø·Ø§Ø¨Ù‚" in content_lower or "Ù…ÙƒØªØ¨" in content_lower:
                content_type_detected = "Ø£Ø±Ù‰ Ø£Ù† Ù‡Ø°Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„Ù…Ø¨Ù†Ù‰. "
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ©
            welcome_messages = [
                "Ø´ÙƒØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ù…Ø´Ø§Ø±ÙƒØ© Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚ÙŠÙ…Ø©! Ù„Ø¬Ø¹Ù„Ù‡Ø§ Ø£ÙƒØ«Ø± ÙØ§Ø¦Ø¯Ø© Ù„Ù„Ø¬Ù…ÙŠØ¹ØŒ Ø£ÙˆØ¯ Ø£Ù† Ø£Ø³Ø£Ù„Ùƒ:",
                "Ù‡Ø°Ù‡ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù…Ø©! Ù„Ø¥Ø«Ø±Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©:",
                "Ø´ÙƒØ±Ø§Ù‹ Ø¬Ø²ÙŠÙ„Ø§Ù‹! Ù„ØªÙˆØ«ÙŠÙ‚ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙÙŠØ¯:"
            ]
            
            import random
            welcome_message = random.choice(welcome_messages)
            
            # Ø¥Ø¶Ø§ÙØ© Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": f"{content_type_detected}{welcome_message}\n\n{first_question}",
                "timestamp": time.time()
            })
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {str(e)}")
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": "Ø¢Ø³ÙØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
                "timestamp": time.time()
            })
            # Reset to normal conversation mode
            st.session_state.conversation_mode = "normal"

def process_knowledge_collection(openai_client, db_client, employee_name, department, answer):
    """Process answer to a follow-up question during knowledge collection"""
    # Ø­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
    current_idx = st.session_state.current_knowledge["question_index"]
    st.session_state.current_knowledge["answers"][current_idx] = answer
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ø¬ÙˆØ§Ø¨ Ø¥Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    current_question = st.session_state.current_knowledge["questions"][current_idx]
    st.session_state.current_knowledge["previous_questions"].append(current_question)
    st.session_state.current_knowledge["previous_answers"].append(answer)
    
    # Ø²ÙŠØ§Ø¯Ø© Ù…Ø¤Ø´Ø± Ø§Ù„Ø³Ø¤Ø§Ù„
    st.session_state.current_knowledge["question_index"] += 1
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒÙ†Ø§ Ù‚Ø¯ Ø·Ø±Ø­Ù†Ø§ 3 Ø£Ø³Ø¦Ù„Ø© (ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰)
    if st.session_state.current_knowledge["question_index"] >= 3:
        # Ù„Ù‚Ø¯ Ø¬Ù…Ø¹Ù†Ø§ ÙƒÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§ØªØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©..."):
            try:
                # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©
                final_knowledge = process_question_answers(
                    openai_client,
                    st.session_state.current_knowledge["processed_text"],
                    st.session_state.current_knowledge["previous_questions"],  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ Ø·Ø±Ø­Ù†Ø§ Ø¨Ø§Ù„ÙØ¹Ù„
                    st.session_state.current_knowledge["previous_answers"]     # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„ØªÙŠ Ø¬Ù…Ø¹Ù†Ø§
                )
                
                # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                tags = generate_knowledge_tags(openai_client, final_knowledge)
                
                # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                knowledge_id = save_knowledge(db_client, final_knowledge, department, employee_name)
                
                # ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ù„Ù‰ Ø£Ù†Ù‡Ø§ Ù…ÙƒØªÙ…Ù„Ø©
                st.session_state.current_knowledge["complete"] = True
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø¨ØªÙ†Ø³ÙŠÙ‚ Ø£ÙƒØ«Ø± ØªÙ†Ø¸ÙŠÙ…Ø§Ù‹
                completion_messages = [
                    "Ø´ÙƒØ±Ø§Ù‹ Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚ÙŠÙ…Ø©. Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¹Ø±ÙØ© Ø´Ø§Ù…Ù„:",
                    "Ø±Ø§Ø¦Ø¹! Ù„Ù‚Ø¯ Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¢Ù†. Ù‚Ù…Øª Ø¨ØªÙ†Ø¸ÙŠÙ… ÙˆØ¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ Ø´Ø§Ø±ÙƒØªÙ‡Ø§ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ù…ØªÙƒØ§Ù…Ù„Ø©:",
                    "Ù…Ù…ØªØ§Ø²! Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¢Ù†. Ù‚Ù…Øª Ø¨Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙˆØªÙ†Ø¸ÙŠÙ…Ù‡Ø§ ÙˆØªØµØ­ÙŠØ­Ù‡Ø§ Ù„ØªØµØ¨Ø­ ÙƒÙ…Ø§ ÙŠÙ„ÙŠ:"
                ]
                
                import random
                completion_message = random.choice(completion_messages)
                
                assistant_message = f"{completion_message}\n\n{final_knowledge}\n\n**Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:** {', '.join(tags)}"
                
                # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": assistant_message,
                    "timestamp": time.time(),
                    "is_knowledge_saved": True
                })
                
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                st.session_state.conversation_mode = "normal"
                
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {str(e)}")
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": "Ø¢Ø³ÙØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
                    "timestamp": time.time()
                })
                # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¥Ù„Ù‰ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                st.session_state.conversation_mode = "normal"
    else:
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø­Ø§Ù„ÙŠ
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©..."):
            try:
                # ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚
                next_questions = generate_smart_questions(
                    openai_client, 
                    st.session_state.current_knowledge["processed_text"],
                    st.session_state.current_knowledge["previous_questions"],
                    st.session_state.current_knowledge["previous_answers"]
                )
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹Ø©
                next_question = next_questions[0] if next_questions else "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù‡Ù…Ø© ØªÙˆØ¯ Ù…Ø´Ø§Ø±ÙƒØªÙ‡Ø§ØŸ"
                
                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                st.session_state.current_knowledge["questions"].append(next_question)
                st.session_state.current_knowledge["answers"].append("")  # Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø­Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
                
                # Ø¥Ø¶Ø§ÙØ© Ù†Øµ ØªØ´Ø¬ÙŠØ¹ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ
                question_prefix = "Ø´ÙƒØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø©! Ù„Ø¯ÙŠ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø± Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø¹Ø±ÙØ©:"
                
                # Ø¥Ø¶Ø§ÙØ© Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": f"{question_prefix}\n\n{next_question}",
                    "timestamp": time.time()
                })
                
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ: {str(e)}")
                
                # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ Ù…Ø¹ OpenAIØŒ Ø§Ø³ØªØ®Ø¯Ù… DummyAI Ù„ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ù…Ù†Ø§Ø³Ø¨
                # Ø§Ù„Ø°ÙŠ Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
                
                # ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø§Ù„Ù…Ø¹Ø±ÙØ© + Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© + Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª)
                content_context = st.session_state.current_knowledge["processed_text"]
                previous_qa = []
                for q, a in zip(st.session_state.current_knowledge["previous_questions"], 
                               st.session_state.current_knowledge["previous_answers"]):
                    previous_qa.append(f"Ø³: {q}")
                    previous_qa.append(f"Ø¬: {a}")
                
                full_context = content_context + "\n\n" + "\n".join(previous_qa)
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ù…Ù†Ø§Ø³Ø¨
                general_questions = [
                    "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø£Ùˆ Ø®Ø·ÙˆØ§Øª Ù…Ø­Ø¯Ø¯Ø© ÙŠØ¬Ø¨ Ø§ØªØ¨Ø§Ø¹Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŸ",
                    "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§ØªØ®Ø§Ø°Ù‡Ø§ Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŸ",
                    "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø¢Ø«Ø§Ø± Ø¬Ø§Ù†Ø¨ÙŠØ© Ø£Ùˆ ØªØ£Ø«ÙŠØ±Ø§Øª Ø¹Ù„Ù‰ Ø£Ù‚Ø³Ø§Ù… Ø£Ùˆ Ù…Ù†Ø§Ø·Ù‚ Ø£Ø®Ø±Ù‰ØŸ",
                    "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ø³Ø¤ÙˆÙ„ Ø£Ùˆ ÙØ±ÙŠÙ‚ Ù…Ø­Ø¯Ø¯ ÙŠØ¬Ø¨ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù‡ ÙÙŠ Ù…Ø«Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø§ØªØŸ",
                    "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù‡Ù…Ø© ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø£Ùˆ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ"
                ]
                
                import random
                fallback_question = random.choice(general_questions)
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ®ØµÙŠØµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚
                # Ù‚Ø§Ù…ÙˆØ³ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ®ØµØµØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                specialized_questions = {
                    "ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ": [
                        "Ù‡Ù„ ØªÙ… Ø¹Ø²Ù„ Ø§Ù„ØªÙŠØ§Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø¹Ù† Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ØªØ¶Ø±Ø±Ø©ØŸ",
                        "Ù‡Ù„ ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¥ØµØ§Ø¨Ø§Øª Ø£Ùˆ Ø£Ø¶Ø±Ø§Ø± Ù†ØªØ¬Øª Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŸ",
                        "Ù‡Ù„ ØªÙ… Ø¥Ø¨Ù„Ø§Øº Ù…Ø³Ø¤ÙˆÙ„ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø£Ùˆ Ù‚Ø³Ù… Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø¨Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªØªØ®Ø° Ù„Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£Ø¬Ø²Ø§Ø¡ Ø£Ø®Ø±Ù‰ Ù…Ù† Ø§Ù„Ù…Ø¨Ù†Ù‰ Ù…ØªØ£Ø«Ø±Ø© Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©ØŸ"
                    ],
                    "Ø­Ø±ÙŠÙ‚": [
                        "Ù‡Ù„ ØªÙ… ØªÙØ¹ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø¥Ù†Ø°Ø§Ø± Ø§Ù„Ø­Ø±ÙŠÙ‚ØŸ",
                        "Ù‡Ù„ ØªÙ… Ø¥Ø®Ù„Ø§Ø¡ Ø§Ù„Ù…Ø¨Ù†Ù‰ ÙˆÙÙ‚Ø§Ù‹ Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø©ØŸ",
                        "Ù…Ø§ Ù‡Ùˆ Ø³Ø¨Ø¨ Ø§Ù„Ø­Ø±ÙŠÙ‚ Ø§Ù„Ù…Ø­ØªÙ…Ù„ØŸ",
                        "Ù‡Ù„ ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ù…Ø¯Ù†ÙŠØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¥ØµØ§Ø¨Ø§Øª Ø£Ùˆ Ø®Ø³Ø§Ø¦Ø± Ø¨Ø´Ø±ÙŠØ©ØŸ",
                        "Ù‡Ù„ ØªÙ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¶Ø±Ø§Ø± Ø§Ù„Ù…Ø§Ø¯ÙŠØ© Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¹Ù† Ø§Ù„Ø­Ø±ÙŠÙ‚ØŸ"
                    ],
                    "Ø¹Ø·Ù„": [
                        "Ù…ØªÙ‰ Ø¨Ø¯Ø£ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø·Ù„ ÙÙŠ Ø§Ù„Ø¸Ù‡ÙˆØ±ØŸ",
                        "Ù‡Ù„ ØªÙ…Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ø·Ù„ Ù…Ù† Ù‚Ø¨Ù„ØŸ",
                        "Ù‡Ù„ Ø§Ù„Ø¹Ø·Ù„ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙŠÙˆÙ…ÙŠØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø¨Ø¯Ø§Ø¦Ù„ Ù…ØªØ§Ø­Ø© Ø£Ø«Ù†Ø§Ø¡ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ø·Ù„ØŸ",
                        "Ù…Ù† Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ù…ØªØ§Ø¨Ø¹Ø© Ø¥ØµÙ„Ø§Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø·Ù„ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù‚Ø·Ø¹ Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥ØµÙ„Ø§Ø­ØŸ"
                    ],
                    "Ù…ÙƒØ§Ù†": [
                        "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ ÙˆÙƒÙŠÙÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ ØªØµØ§Ø±ÙŠØ­ Ø®Ø§ØµØ© Ø£Ùˆ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø£Ù…Ù†ÙŠØ© Ù„Ù„ÙˆØµÙˆÙ„ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù†ØŸ",
                        "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„Ø°ÙŠÙ† ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ³ØªÙˆØ¹Ø¨Ù‡Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù†ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙˆÙ‚Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„Ø¹Ù…Ù„ Ø£Ùˆ Ø§Ù„Ø²ÙŠØ§Ø±Ø©ØŸ",
                        "Ù…Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù† ÙˆÙƒÙŠÙÙŠØ© Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù‡ØŸ"
                    ],
                    "Ù…ÙˆØ¸Ù": [
                        "Ù…Ø§ Ù‡Ùˆ Ø¯ÙˆØ± Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆÙ…Ø³Ø¤ÙˆÙ„ÙŠØ§ØªÙ‡ØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸ÙØŸ",
                        "Ù…Ø§ Ù‡ÙŠ Ø³Ø§Ø¹Ø§Øª Ø¹Ù…Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸Ù Ø£Ùˆ Ù…ÙˆØ§Ø¹ÙŠØ¯ ØªÙˆØ§Ø¬Ø¯Ù‡ØŸ",
                        "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø¨Ø¯ÙŠÙ„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸Ù ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆØ§Ø¬Ø¯Ù‡ØŸ",
                        "Ù‡Ù„ ÙŠÙ…Ù„Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸Ù ØµÙ„Ø§Ø­ÙŠØ§Øª Ø®Ø§ØµØ© Ø£Ùˆ Ø®Ø¨Ø±Ø§Øª Ù…Ø­Ø¯Ø¯Ø©ØŸ",
                        "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù‚Ø³Ù… Ø£Ùˆ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙŠ ÙŠØªØ¨Ø¹ Ù„Ù‡Ø§ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¸ÙØŸ"
                    ]
                }
                
                # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
                content_types = {
                    "ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ": ["ÙƒÙ‡Ø±Ø¨Ø§Ø¡", "ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ", "ØªÙ…Ø§Ø³", "ÙÙˆÙ„Øª", "Ø£Ø³Ù„Ø§Ùƒ", "ØªÙŠØ§Ø±"],
                    "Ø­Ø±ÙŠÙ‚": ["Ø­Ø±ÙŠÙ‚", "Ø¯Ø®Ø§Ù†", "Ø­Ø±Ø§Ø±Ø©", "Ù„Ù‡Ø¨", "Ø¥Ø·ÙØ§Ø¡", "Ø·ÙØ§ÙŠØ©"],
                    "Ø¹Ø·Ù„": ["Ø¹Ø·Ù„", "Ø®Ù„Ù„", "ØµÙŠØ§Ù†Ø©", "Ø¥ØµÙ„Ø§Ø­", "ØªØµÙ„ÙŠØ­", "Ù…Ø¹Ø·Ù„", "ØªÙˆÙ‚Ù"],
                    "Ù…ÙƒØ§Ù†": ["Ù…ÙƒØ§Ù†", "ØºØ±ÙØ©", "Ù…ÙƒØªØ¨", "Ø·Ø§Ø¨Ù‚", "Ø¯ÙˆØ±", "Ù…Ø¨Ù†Ù‰", "Ù‚Ø§Ø¹Ø©"],
                    "Ù…ÙˆØ¸Ù": ["Ù…ÙˆØ¸Ù", "Ù…Ø¯ÙŠØ±", "Ø¹Ø§Ù…Ù„", "Ù…Ø´Ø±Ù", "Ù…Ù‡Ù†Ø¯Ø³", "ÙÙ†ÙŠ", "Ù…Ø³Ø¤ÙˆÙ„"]
                }
                
                # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                detected_type = None
                max_matches = 0
                
                for content_type, keywords in content_types.items():
                    matches = sum(1 for word in keywords if word in full_context.lower())
                    if matches > max_matches:
                        max_matches = matches
                        detected_type = content_type
                
                # Ø¥Ø°Ø§ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ®ØµØµØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                if detected_type and detected_type in specialized_questions:
                    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ù…Ø§ Ø³Ø¨Ù‚ Ø·Ø±Ø­Ù‡
                    previous_questions = st.session_state.current_knowledge["previous_questions"]
                    available_questions = [q for q in specialized_questions[detected_type] 
                                          if not any(are_questions_similar(q, prev_q) for prev_q in previous_questions)]
                    
                    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ¨Ù‚ÙŠØ©ØŒ Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§
                    if available_questions:
                        fallback_question = random.choice(available_questions)
                    else:
                        # Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ®ØµØµØ©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø©
                        fallback_question = random.choice(general_questions)
                else:
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø³Ø¤Ø§Ù„Ù‹Ø§ Ø¹Ø§Ù…Ù‹Ø§
                    fallback_question = random.choice(general_questions)
                
                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø­Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©
                st.session_state.current_knowledge["questions"].append(fallback_question)
                st.session_state.current_knowledge["answers"].append("")
                
                # Ø¥Ø¶Ø§ÙØ© Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…ÙˆÙ„Ø¯
                response_prefixes = [
                    "Ø£ÙÙ‡Ù…. Ù„Ø¯ÙŠ Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ù‡Ù…: ",
                    "Ø´ÙƒØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª. Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø©: ",
                    "Ù‡Ø°Ø§ ÙŠØ³Ø§Ø¹Ø¯Ù†ÙŠ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„ÙˆØ¶Ø¹ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„. Ø³Ø¤Ø§Ù„ÙŠ Ø§Ù„ØªØ§Ù„ÙŠ: "
                ]
                
                response_prefix = random.choice(response_prefixes)
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": f"{response_prefix}{fallback_question}",
                    "timestamp": time.time()
                })

def show_chat_interface(openai_client, db_client):
    """Display the chat interface for knowledge sharing"""
    st.title("Ù…Ù†ØµØ© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
    
    # Initialize session states
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "conversation_mode" not in st.session_state:
        st.session_state.conversation_mode = "normal"  # normal, knowledge_collection, search
        
    if "current_knowledge" not in st.session_state:
        st.session_state.current_knowledge = {
            "original_text": "",
            "processed_text": "",
            "question_index": 0,  # Current question index (0-2)
            "questions": [],      # List of smart questions
            "answers": [],        # List of answers to questions
            "previous_questions": [],  # Ø³Ø¬Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            "previous_answers": [],    # Ø³Ø¬Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            "complete": False     # Whether knowledge collection is complete
        }
    
    # Get user information in sidebar
    with st.sidebar:
        st.header("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        employee_name = st.text_input("Ø§Ù„Ø§Ø³Ù…:", key="employee_name")
        department = st.selectbox(
            "Ø§Ù„Ù‚Ø³Ù…:", 
            options=get_sample_departments(),
            key="user_department"
        )
        
        st.markdown("---")
        
        # Mode selection
        st.subheader("ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
        if st.button("Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹Ø±ÙØ© Ø¬Ø¯ÙŠØ¯Ø©", use_container_width=True):
            # Reset the conversation mode to normal to start fresh
            st.session_state.conversation_mode = "normal"
            st.rerun()
            
        if st.button("Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©", use_container_width=True):
            # Set to search mode
            st.session_state.conversation_mode = "search"
            
            # Add system message to indicate search mode
            if not any(msg.get("is_search_mode", False) for msg in st.session_state.chat_history):
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ØŸ",
                    "timestamp": time.time(),
                    "is_search_mode": True
                })
            st.rerun()
        
        # Clear chat history button
        if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.conversation_mode = "normal"
            st.session_state.current_knowledge = {
                "original_text": "",
                "processed_text": "",
                "question_index": 0,
                "questions": [],
                "answers": [],
                "previous_questions": [],  # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø³Ø¬Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                "previous_answers": [],    # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø³Ø¬Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª
                "complete": False
            }
            st.rerun()
    
    # Main chat area
    chat_container = st.container()
    
    with chat_container:
        # Style for the chat messages
        st.markdown("""
        <style>
        .user-message {
            background-color: #e9f5ff;
            padding: 10px 15px;
            border-radius: 15px;
            margin: 5px 0;
            text-align: right;
            direction: rtl;
        }
        .assistant-message {
            background-color: #f0f0f0;
            padding: 10px 15px;
            border-radius: 15px;
            margin: 5px 0;
            direction: rtl;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ù†Øµ Ù…ØµØ­Ø­
                st.markdown(f"<div class='user-message'>{message['content']}</div>", unsafe_allow_html=True)
                
                # Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ ØªØµØ­ÙŠØ­Ø§Øª Ø¬ÙˆÙ‡Ø±ÙŠØ©
                if message.get("original_text") and message.get("original_text") != message['content']:
                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ© (Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ø±ÙˆÙ Ø¹Ù„Ø© Ø£Ùˆ ØªØ±Ù‚ÙŠÙ…)
                    if len(set(message.get("original_text")).symmetric_difference(set(message['content']))) > 3:
                        with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ"):
                            st.text(message.get("original_text"))
            else:
                # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
                st.markdown(f"<div class='assistant-message'>{message['content']}</div>", unsafe_allow_html=True)
                
                # Ø¹Ø±Ø¶ Ù…Ø¤Ø´Ø± Ù†Ø¬Ø§Ø­ Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©
                if message.get("is_knowledge_saved", False):
                    st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ù†Ø¬Ø§Ø­!")
    
    # Input area at bottom
    st.write("---")
    
    # User input field
    user_input = st.text_area(
        "Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:",
        height=100,
        key="user_message"
    )
    
    # Send button
    if st.button("Ø¥Ø±Ø³Ø§Ù„", use_container_width=True, key="send_message"):
        if not user_input.strip():
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø±Ø³Ø§Ù„Ø© Ø£ÙˆÙ„Ø§Ù‹.")
            return
        
        if not employee_name.strip():
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù…Ùƒ ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.")
            return
        
        # ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙÙŠ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        corrected_input = correct_arabic_text(user_input)
        
        # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ù…Ø¹ Ø§Ù„ØªØµØ­ÙŠØ­)
        st.session_state.chat_history.append({
            "role": "user",
            "content": corrected_input,  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­
            "original_text": user_input,  # Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
            "timestamp": time.time()
        })
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­)
        if st.session_state.conversation_mode == "search":
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­
            process_search_query(openai_client, db_client, corrected_input)
            
        elif st.session_state.conversation_mode == "knowledge_collection":
            # Ù†Ø­Ù† ÙÙŠ Ù…Ù†ØªØµÙ Ø¹Ù…Ù„ÙŠØ© Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©
            process_knowledge_collection(openai_client, db_client, employee_name, department, corrected_input)
            
        else:  # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ - Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ù‡Ø°Ù‡ Ù…Ø¹Ø±ÙØ© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ©
            # Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ©
            start_knowledge_collection(openai_client, db_client, employee_name, department, corrected_input)
            
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­ Ù…Ø®ØªÙ„ÙÙ‹Ø§ Ø¹Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø£Ø¸Ù‡Ø± Ù…Ù„Ø§Ø­Ø¸Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        if corrected_input != user_input:
            st.info("ğŸ‘¨â€ğŸ’» ØªÙ… ØªØµØ­ÙŠØ­ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª.")
        
        # Rerun to update the UI
        st.rerun()
